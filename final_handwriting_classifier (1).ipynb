{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79fd5efd-786f-4e0d-a119-67feea5dadea",
   "metadata": {},
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52812a19-9aa1-4a9a-937d-2a65df14c228",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. í”„ë¡œì íŠ¸ ê°œìš”\n",
    "- ìˆ«ì(0~9)ì™€ í•œê¸€ ìëª¨(ã„±~ã…)ë¥¼ ë¶„ë¥˜í•˜ëŠ” OCR ë”¥ëŸ¬ë‹ ëª¨ë¸\n",
    "- CNN êµ¬ì¡°ë¥¼ ì‚¬ìš©í•˜ë©° ì„±ëŠ¥ í–¥ìƒ ê¸°ë²• ì ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "651d3894-f772-4daa-9b75-7fae1ad4bc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b98e65-0870-4f32-82b6-c84cfba88f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“˜ 1. í”„ë¡œì íŠ¸ ê°œìš” (ë§ˆí¬ë‹¤ìš´ ì…€)\n",
    "# ìˆ«ì(0~9)ì™€ í•œê¸€ ìëª¨(ã„±~ã…)ë¥¼ ë¶„ë¥˜í•˜ëŠ” CNN ê¸°ë°˜ ì†ê¸€ì”¨ OCR ëª¨ë¸ì…ë‹ˆë‹¤.\n",
    "# CNN ê¸°ë³¸ ëª¨ë¸ê³¼ ì„±ëŠ¥ í–¥ìƒ ê¸°ë²•(Augmentation, Dropout, BatchNorm ë“±)ì„ ì‹¤í—˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "# ğŸ§  2. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# ğŸ“‚ 3. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° í•¨ìˆ˜\n",
    "def load_data(data_dir, img_size=(28, 28)):\n",
    "    images, labels = [], []\n",
    "    class_names = sorted(os.listdir(data_dir))\n",
    "    label_dict = {name: i for i, name in enumerate(class_names)}\n",
    "\n",
    "    for class_name in class_names:\n",
    "        for fname in os.listdir(os.path.join(data_dir, class_name)):\n",
    "            img = load_img(os.path.join(data_dir, class_name, fname), target_size=img_size, color_mode='grayscale')\n",
    "            img = img_to_array(img) / 255.0\n",
    "            images.append(img)\n",
    "            labels.append(label_dict[class_name])\n",
    "\n",
    "    return np.array(images), to_categorical(labels), label_dict\n",
    "\n",
    "# ğŸ“ 4. ë°ì´í„° ë¡œë”© ë° ë¶„í• \n",
    "X, y, label_dict = load_data('./handwritten_sample_english/')\n",
    "X = X.reshape(-1, 28, 28, 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ğŸ”„ 5. ë°ì´í„° ì¦ê°•\n",
    "aug = ImageDataGenerator(\n",
    "    rotation_range=10, width_shift_range=0.1,\n",
    "    height_shift_range=0.1, zoom_range=0.1\n",
    ")\n",
    "aug.fit(X_train)\n",
    "\n",
    "# ğŸ”” 6. ì½œë°± í•¨ìˆ˜ ì„¤ì •\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=5, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(patience=3, factor=0.5)\n",
    "]\n",
    "\n",
    "# ğŸ—ï¸ 7. ëª¨ë¸ êµ¬ì„± (ì„±ëŠ¥ ê°œì„  í¬í•¨)\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_dict), activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# ğŸš€ 8. ëª¨ë¸ í•™ìŠµ\n",
    "history = model.fit(aug.flow(X_train, y_train, batch_size=64),\n",
    "                    epochs=30, validation_split=0.1,\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "# ğŸ§ª 9. í‰ê°€ ë° ì •í™•ë„ ì¶œë ¥\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(\"ìµœì¢… í…ŒìŠ¤íŠ¸ ì •í™•ë„:\", test_acc)\n",
    "\n",
    "# ğŸ–¼ï¸ 10. ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”\n",
    "pred = model.predict(X_test)\n",
    "plt.figure(figsize=(15, 3))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i + 1)\n",
    "    plt.imshow(X_test[i].reshape(28, 28), cmap='gray')\n",
    "    true_label = list(label_dict.keys())[np.argmax(y_test[i])]\n",
    "    pred_label = list(label_dict.keys())[np.argmax(pred[i])]\n",
    "    plt.title(f\"T:{true_label}\\nP:{pred_label}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a870861-c4de-478a-b0c0-6af97b0a50ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e511b2-f003-453d-8a79-f666cd88527a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
